{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQAL/ZzhQI1xmkudkNL1gN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanika0216/python-Basics/blob/main/Evaluation_Metrics_and_Regression_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Theoretical**\n",
        "\n",
        "Q1. What does R-squared represent in a regression model?\n",
        "\n",
        "Ans: R-squared batata hai ki model dependent variable ke variance ka kitna hissa explain karta hai.\n",
        "\n",
        "Q2. What are the assumptions of linear regression?\n",
        "\n",
        "Ans: Linear regression ke assumptions hain: linearity, independence, homoscedasticity, normality of residuals, aur no multicollinearity.\n",
        "\n",
        "Q3. What is the difference between R-squared and Adjusted R-squared?\n",
        "\n",
        "Ans: Adjusted R-squared R-squared se better hota hai kyunki yeh predictors ki sankhya ko consider karta hai.\n",
        "\n",
        "Q4. Why do we use Mean Squared Error (MSE)?\n",
        "\n",
        "Ans: MSE prediction errors ka square le kar unhe average karta hai, jisse large errors zyada penalize hote hain.\n",
        "\n",
        "Q5. What does an Adjusted R-squared value of 0.85 indicate?\n",
        "\n",
        "Ans: Model 85% variance ko predictors ke through accurately explain karta hai, complexity ko adjust karte hue.\n",
        "\n",
        "Q6. How do we check for normality of residuals in linear regression?\n",
        "\n",
        "Ans: Q-Q plot, histogram, aur Shapiro-Wilk jaise tests ka use kar ke residuals ki normality check ki ja sakti hai.\n",
        "\n",
        "Q7. What is multicollinearity, and how does it impact regression?\n",
        "\n",
        "Ans: Multicollinearity tab hota hai jab independent variables aapas me strongly correlated hote hain, jisse coefficients unstable ho jate hain.\n",
        "\n",
        "Q8. What is Mean Absolute Error (MAE)?\n",
        "\n",
        "Ans: MAE actual aur predicted values ke beech ke absolute differences ka average hota hai.\n",
        "\n",
        "Q9. What are the benefits of using an ML pipeline?\n",
        "\n",
        "Ans: ML pipeline automation, consistency, and reproducibility ko ensure karta hai in preprocessing and modeling steps.\n",
        "\n",
        "Q10. Why is RMSE considered more interpretable than MSE?\n",
        "\n",
        "Ans: RMSE units me hota hai same as target variable, isliye human interpretation ke liye better hota hai.\n",
        "\n",
        "Q11. What is pickling in Python, and how is it useful in ML?\n",
        "\n",
        "Ans: Pickling Python objects ko byte stream me convert karta hai, jisse trained ML models ko save/load kiya ja sakta hai.\n",
        "\n",
        "Q12. What does a high R-squared value mean?\n",
        "\n",
        "Ans: High R-squared ka matlab model target variable ke variation ko achhi tarah explain karta hai.\n",
        "\n",
        "Q13. What happens if linear regression assumptions are violated?\n",
        "\n",
        "Ans: Model inaccurate ho sakta hai, coefficients biased ho sakte hain, aur predictions unreliable ho jate hain.\n",
        "\n",
        "Q14. How can we address multicollinearity in regression?\n",
        "\n",
        "Ans: Multicollinearity ko handle karne ke liye VIF check karke variables drop karte hain ya regularization (Ridge/Lasso) use karte hain.\n",
        "\n",
        "Q15. How can feature selection improve model performance in regression analysis?\n",
        "\n",
        "Ans: Feature selection unnecessary variables ko hata ke overfitting reduce karta hai aur model interpretability improve karta hai.\n",
        "\n",
        "Q16. How is Adjusted R-squared calculated?\n",
        "\n",
        "Ans: Adjusted R-squared formula: 1 - [(1 - R²)(n - 1)/(n - k - 1)], jahan n = observations, k = predictors.\n",
        "\n",
        "Q17. Why is MSE sensitive to outliers?\n",
        "\n",
        "Ans: Outliers ke errors square hone ki wajah se MSE unhe disproportionately penalize karta hai.\n",
        "\n",
        "Q18. What is the role of homoscedasticity in linear regression?\n",
        "\n",
        "Ans: Homoscedasticity ensure karta hai ki errors ka variance same rahe across all levels of predictors.\n",
        "\n",
        "Q19. What is Root Mean Squared Error (RMSE)?\n",
        "\n",
        "Ans: RMSE prediction errors ka square root of average square difference hota hai — target variable ke units me.\n",
        "\n",
        "Q20. Why is pickling considered risky?\n",
        "\n",
        "Ans: Pickling arbitrary code execute kar sakta hai agar unsafe source se load kiya jaye — security threat hota hai.\n",
        "\n",
        "Q21. What alternatives exist to pickling for saving ML models?\n",
        "\n",
        "Ans: Alternatives hain: joblib, ONNX, PMML, aur h5 (specially for deep learning models).\n",
        "\n",
        "Q22. What is heteroscedasticity, and why is it a problem?\n",
        "\n",
        "Ans: Heteroscedasticity tab hota hai jab residuals ka variance consistent nahi hota — standard errors unreliable ho jate hain.\n",
        "\n",
        "Q23. How can interaction terms enhance a regression model's predictive power?\n",
        "\n",
        "Ans: Interaction terms variables ke combined effect ko capture karte hain, jo individual effect se alag hota hai."
      ],
      "metadata": {
        "id": "I_VesZ9b9Wb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practical**\n",
        "\n",
        "Q1. Write a Python script to visualize the distribution of errors (residuals) for a multiple linear regression model using Seaborn's \"diamonds\" dataset."
      ],
      "metadata": {
        "id": "22VlIHc1-bVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and clean data\n",
        "data = sns.load_dataset(\"diamonds\").dropna()\n",
        "data = data.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "# Define features and target\n",
        "X = data.drop(\"price\", axis=1)\n",
        "y = data[\"price\"]\n",
        "\n",
        "# Add constant and fit model\n",
        "X = sm.add_constant(X)\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Get residuals\n",
        "residuals = model.resid\n",
        "\n",
        "# Plot residuals distribution\n",
        "sns.histplot(residuals, kde=True)\n",
        "plt.title(\"Residuals Distribution\")\n",
        "plt.xlabel(\"Residuals\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Qp4wNTdb-xzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. Write a Python script to calculate and print Mean Squared Error (MSE), Mean Absolute Error (MAE), and Root Mean Squared Error (RMSE) for a linear regression model."
      ],
      "metadata": {
        "id": "gUw8ahdx-0Hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Example data\n",
        "y_true = [3, -0.5, 2, 7]\n",
        "y_pred = [2.5, 0.0, 2, 8]\n",
        "\n",
        "# Calculate errors\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "# Print results\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"RMSE:\", rmse)\n"
      ],
      "metadata": {
        "id": "fzE9OGNd-0TD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Write a Python script to check if the assumptions of linear regression are met. Use a scatter plot to check linearity, residuals plot for homoscedasticity, and correlation matrix for multicollinearity."
      ],
      "metadata": {
        "id": "uAOVFbQX-0iS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "# Load and clean data\n",
        "data = sns.load_dataset('diamonds')\n",
        "data = data.select_dtypes(include=['float64', 'int64']).dropna()\n",
        "\n",
        "# Define features and target\n",
        "X = data.drop('price', axis=1)\n",
        "y = data['price']\n",
        "\n",
        "# Fit model\n",
        "X = sm.add_constant(X)\n",
        "model = sm.OLS(y, X).fit()\n",
        "residuals = model.resid\n",
        "fitted = model.fittedvalues\n",
        "\n",
        "# Linearity check\n",
        "sns.scatterplot(x=fitted, y=y)\n",
        "plt.title(\"Linearity: Fitted vs Actual\")\n",
        "plt.xlabel(\"Fitted Values\")\n",
        "plt.ylabel(\"Actual Values\")\n",
        "plt.show()\n",
        "\n",
        "# Homoscedasticity check\n",
        "sns.scatterplot(x=fitted, y=residuals)\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.title(\"Homoscedasticity: Residuals vs Fitted\")\n",
        "plt.xlabel(\"Fitted Values\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.show()\n",
        "\n",
        "# Multicollinearity check\n",
        "corr_matrix = X.drop('const', axis=1).corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kwJH6TGJ-0nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Write a Python script that creates a machine learning pipeline with feature scaling and evaluates the performance of different regression models."
      ],
      "metadata": {
        "id": "c01fGj6I-0tT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Create synthetic dataset\n",
        "X, y = make_regression(n_samples=100, n_features=5, noise=10, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define pipelines\n",
        "models = {\n",
        "    \"LinearRegression\": LinearRegression(),\n",
        "    \"RidgeRegression\": Ridge()\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    pipe = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('regressor', model)\n",
        "    ])\n",
        "    pipe.fit(X_train, y_train)\n",
        "    preds = pipe.predict(X_test)\n",
        "    print(f\"{name} R² Score: {r2_score(y_test, preds):.4f}\")\n"
      ],
      "metadata": {
        "id": "NNLS7Pp7-0zD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Implement a simple linear regression model on a dataset and print the model's coefficients, intercept, and R-squared score."
      ],
      "metadata": {
        "id": "cCR7oYg2-04p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generate synthetic dataset\n",
        "X, y = make_regression(n_samples=100, n_features=1, noise=5, random_state=0)\n",
        "\n",
        "# Fit model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Print results\n",
        "print(\"Coefficient:\", model.coef_[0])\n",
        "print(\"Intercept:\", model.intercept_)\n",
        "print(\"R² Score:\", model.score(X, y))\n"
      ],
      "metadata": {
        "id": "9cI2U8Ne-0-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Write a Python script that analyzes the relationship between total bill and tip in the 'tips' dataset using simple linear regression and visualizes the results."
      ],
      "metadata": {
        "id": "GgaLxml3-1EI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "data = sns.load_dataset('tips')\n",
        "\n",
        "# Prepare data\n",
        "X = data[['total_bill']]\n",
        "y = data['tip']\n",
        "\n",
        "# Fit model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict and plot\n",
        "sns.scatterplot(x='total_bill', y='tip', data=data)\n",
        "plt.plot(data['total_bill'], model.predict(X), color='red')\n",
        "plt.title(\"Total Bill vs Tip (Linear Regression)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qSeLSMIj-1J4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. Write a Python script that fits a linear regression model to a synthetic dataset with one feature. Use the model to predict new values and plot the data points along with the regression line."
      ],
      "metadata": {
        "id": "NSZaFlsj-1Q3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generate data\n",
        "X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=1)\n",
        "\n",
        "# Fit model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Plot\n",
        "plt.scatter(X, y, color='blue')\n",
        "plt.plot(X, model.predict(X), color='red')\n",
        "plt.title(\"Synthetic Data with Regression Line\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GNL5FZkB-1WZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. Write a Python script that pickles a trained linear regression model and saves it to a file."
      ],
      "metadata": {
        "id": "xI1snR2A-1bH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Train model\n",
        "X, y = make_regression(n_samples=100, n_features=1, noise=5, random_state=0)\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Save model\n",
        "with open('linear_model.pkl', 'wb') as file:\n",
        "    pickle.dump(model, file)\n",
        "\n",
        "print(\"Model pickled and saved as 'linear_model.pkl'\")\n"
      ],
      "metadata": {
        "id": "Tdlog3gS-1go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. Write a Python script that fits a polynomial regression model (degree 2) to a dataset and plots the regression curve."
      ],
      "metadata": {
        "id": "zywLdPkm-1lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Generate synthetic data\n",
        "X = np.random.rand(100, 1) * 10\n",
        "y = 3 * X**2 + 2 * X + 5 + np.random.randn(100, 1) * 10\n",
        "\n",
        "# Polynomial transformation\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Fit model\n",
        "model = LinearRegression()\n",
        "model.fit(X_poly, y)\n",
        "\n",
        "# Predict and plot\n",
        "X_sorted = np.sort(X, axis=0)\n",
        "y_pred = model.predict(poly.transform(X_sorted))\n",
        "\n",
        "plt.scatter(X, y, color='blue')\n",
        "plt.plot(X_sorted, y_pred, color='red')\n",
        "plt.title(\"Polynomial Regression (Degree 2)\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qPpslywH-1rJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10. Generate synthetic data for simple linear regression (use random values for X and y) and fit a linear regression model to the data. Print the model's coefficient and intercept."
      ],
      "metadata": {
        "id": "U5CxFZTs-1wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Generate random data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 1) * 10\n",
        "y = 4 * X + 6 + np.random.randn(100, 1) * 2\n",
        "\n",
        "# Fit model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Print parameters\n",
        "print(\"Coefficient:\", model.coef_[0][0])\n",
        "print(\"Intercept:\", model.intercept_[0])\n"
      ],
      "metadata": {
        "id": "bWbf4ho6-11s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q11. Write a Python script that fits polynomial regression models of different degrees to a synthetic dataset and compares their performance."
      ],
      "metadata": {
        "id": "qKFiL6UX-16M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Synthetic data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 1) * 10\n",
        "y = 2 * X**3 - 5 * X**2 + X + 10 + np.random.randn(100, 1) * 20\n",
        "\n",
        "# Fit models of degree 1 to 4\n",
        "for degree in range(1, 5):\n",
        "    poly = PolynomialFeatures(degree)\n",
        "    X_poly = poly.fit_transform(X)\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_poly, y)\n",
        "    y_pred = model.predict(X_poly)\n",
        "    print(f\"Degree {degree} R² Score: {r2_score(y, y_pred):.4f}\")\n"
      ],
      "metadata": {
        "id": "P1NuEh51-1_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q12. Write a Python script that fits a simple linear regression model with two features and prints the model's coefficients, intercept, and R-squared score."
      ],
      "metadata": {
        "id": "M68zIt-h-2Es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Synthetic data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 2) * 10\n",
        "y = 5 * X[:, 0] + 3 * X[:, 1] + 7 + np.random.randn(100) * 2\n",
        "\n",
        "# Fit model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Print results\n",
        "print(\"Coefficients:\", model.coef_)\n",
        "print(\"Intercept:\", model.intercept_)\n",
        "print(\"R² Score:\", model.score(X, y))\n"
      ],
      "metadata": {
        "id": "e9oNpHC--2J7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q13. Write a Python script that generates synthetic data, fits a linear regression model, and visualizes the regression line along with the data points."
      ],
      "metadata": {
        "id": "SHvCzjY8-2Pc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Synthetic data\n",
        "X = np.random.rand(100, 1) * 10\n",
        "y = 3 * X + 7 + np.random.randn(100, 1) * 5\n",
        "\n",
        "# Fit model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict and plot\n",
        "plt.scatter(X, y, color='blue')\n",
        "plt.plot(X, model.predict(X), color='red')\n",
        "plt.title(\"Linear Regression on Synthetic Data\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "66a4rfCA-2Uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q14. Write a Python script that uses the Variance Inflation Factor (VIF) to check for multicollinearity in a dataset with multiple features."
      ],
      "metadata": {
        "id": "0iAaLvS4-2Z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generate synthetic data\n",
        "X, _ = make_regression(n_samples=100, n_features=5, noise=0.1)\n",
        "df = pd.DataFrame(X, columns=[f\"X{i+1}\" for i in range(X.shape[1])])\n",
        "\n",
        "# Calculate VIF\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Feature\"] = df.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
        "\n",
        "print(vif_data)\n"
      ],
      "metadata": {
        "id": "7lx8p2AR-2ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q15. Write a Python script that generates synthetic data for a polynomial relationship (degree 4), fits a polynomial regression model, and plots the regression curve."
      ],
      "metadata": {
        "id": "yu_6y3ql-2kP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Generate data\n",
        "X = np.random.rand(100, 1) * 10\n",
        "y = 1.5 * X**4 - 2 * X**3 + 3 * X**2 + 5 * X + 7 + np.random.randn(100, 1) * 100\n",
        "\n",
        "# Polynomial regression\n",
        "poly = PolynomialFeatures(degree=4)\n",
        "X_poly = poly.fit_transform(X)\n",
        "model = LinearRegression()\n",
        "model.fit(X_poly, y)\n",
        "\n",
        "# Predict and plot\n",
        "X_sorted = np.sort(X, axis=0)\n",
        "y_pred = model.predict(poly.transform(X_sorted))\n",
        "\n",
        "plt.scatter(X, y, color='blue')\n",
        "plt.plot(X_sorted, y_pred, color='red')\n",
        "plt.title(\"Polynomial Regression (Degree 4)\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HdvJtSr9-2pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q16. Write a Python script that creates a machine learning pipeline with data standardization and a multiple linear regression model, and prints the R-squared score."
      ],
      "metadata": {
        "id": "prrruXop-2uS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate synthetic data\n",
        "X, y = make_regression(n_samples=100, n_features=4, noise=10, random_state=42)\n",
        "\n",
        "# Create pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', LinearRegression())\n",
        "])\n",
        "\n",
        "# Split and train\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Score\n",
        "r2 = pipeline.score(X_test, y_test)\n",
        "print(\"R-squared score:\", r2)\n"
      ],
      "metadata": {
        "id": "83SxIzzC-2zQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q17. Write a Python script that performs polynomial regression (degree 3) on a synthetic dataset and plots the regression curve."
      ],
      "metadata": {
        "id": "KIMPrjBf-24g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Generate data\n",
        "X = np.linspace(0, 10, 100).reshape(-1, 1)\n",
        "y = 0.5 * X**3 - 2 * X**2 + 3 * X + 5 + np.random.randn(100, 1) * 20\n",
        "\n",
        "# Polynomial regression\n",
        "poly = PolynomialFeatures(degree=3)\n",
        "X_poly = poly.fit_transform(X)\n",
        "model = LinearRegression()\n",
        "model.fit(X_poly, y)\n",
        "\n",
        "# Plot\n",
        "plt.scatter(X, y, color='blue')\n",
        "plt.plot(X, model.predict(X_poly), color='red')\n",
        "plt.title(\"Polynomial Regression (Degree 3)\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4m3EFS6F-29g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q18. Write a Python script that performs multiple linear regression on a synthetic dataset with 5 features. Print the R-squared score and model coefficients."
      ],
      "metadata": {
        "id": "MsM8c5G--3Cg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Generate data\n",
        "X, y = make_regression(n_samples=100, n_features=5, noise=10, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Output\n",
        "print(\"R² Score:\", model.score(X, y))\n",
        "print(\"Coefficients:\", model.coef_)\n"
      ],
      "metadata": {
        "id": "ztMqPPsZ-3HC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q19. Write a Python script that generates synthetic data for linear regression, fits a model, and visualizes the data points along with the regression line."
      ],
      "metadata": {
        "id": "58YxH2d8-3Lz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Data\n",
        "X = np.random.rand(100, 1) * 10\n",
        "y = 4 * X + 7 + np.random.randn(100, 1) * 5\n",
        "\n",
        "# Model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Plot\n",
        "plt.scatter(X, y, color='blue')\n",
        "plt.plot(X, model.predict(X), color='red')\n",
        "plt.title(\"Linear Regression on Synthetic Data\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "k3Lp8jLT-3QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q20. Create a synthetic dataset with 3 features and perform multiple linear regression. Print the model's R-squared score and coefficients."
      ],
      "metadata": {
        "id": "RfrwcHsF-3V3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Generate data\n",
        "X = np.random.rand(100, 3)\n",
        "y = 2 * X[:, 0] + 3 * X[:, 1] + 4 * X[:, 2] + 5 + np.random.randn(100)\n",
        "\n",
        "# Model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Output\n",
        "print(\"R² Score:\", model.score(X, y))\n",
        "print(\"Coefficients:\", model.coef_)\n"
      ],
      "metadata": {
        "id": "fBXtR7Os-3ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q21. Write a Python script that demonstrates how to serialize and deserialize machine learning models using joblib instead of pickling."
      ],
      "metadata": {
        "id": "EcDForaE_2kr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import make_regression\n",
        "import joblib\n",
        "\n",
        "# Generate data\n",
        "X, y = make_regression(n_samples=100, n_features=1, noise=5, random_state=0)\n",
        "\n",
        "# Train model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Save model using joblib\n",
        "joblib.dump(model, 'linear_model_joblib.pkl')\n",
        "\n",
        "# Load model\n",
        "loaded_model = joblib.load('linear_model_joblib.pkl')\n",
        "\n",
        "# Confirm it's working\n",
        "print(\"Loaded Model Coefficient:\", loaded_model.coef_[0])\n"
      ],
      "metadata": {
        "id": "r5ww1RqO_2yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q22. Write a Python script to perform linear regression with categorical features using one-hot encoding. Use the Seaborn 'tips' dataset."
      ],
      "metadata": {
        "id": "fDOC74Wp_27o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load dataset\n",
        "data = sns.load_dataset('tips')\n",
        "\n",
        "# Features & target\n",
        "X = data[['total_bill', 'sex', 'smoker', 'day', 'time']]\n",
        "y = data['tip']\n",
        "\n",
        "# One-hot encode categorical columns\n",
        "categorical = ['sex', 'smoker', 'day', 'time']\n",
        "numeric = ['total_bill']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('cat', OneHotEncoder(drop='first'), categorical)\n",
        "], remainder='passthrough')\n",
        "\n",
        "# Pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('encoder', preprocessor),\n",
        "    ('model', LinearRegression())\n",
        "])\n",
        "\n",
        "# Train\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Result\n",
        "print(\"R² Score:\", pipeline.score(X_test, y_test))\n"
      ],
      "metadata": {
        "id": "SPa6KzgE_3El"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q23. Compare Ridge Regression with Linear Regression on a synthetic dataset and print the coefficients and R-squared score."
      ],
      "metadata": {
        "id": "ASLRyFOF_3Om"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "\n",
        "# Generate data\n",
        "X, y = make_regression(n_samples=100, n_features=5, noise=10, random_state=42)\n",
        "\n",
        "# Linear Regression\n",
        "lr = LinearRegression()\n",
        "lr.fit(X, y)\n",
        "print(\"Linear Regression R²:\", lr.score(X, y))\n",
        "print(\"Linear Coefficients:\", lr.coef_)\n",
        "\n",
        "# Ridge Regression\n",
        "ridge = Ridge(alpha=1.0)\n",
        "ridge.fit(X, y)\n",
        "print(\"Ridge Regression R²:\", ridge.score(X, y))\n",
        "print(\"Ridge Coefficients:\", ridge.coef_)\n"
      ],
      "metadata": {
        "id": "nRWS7rz6_3Wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q24. Write a Python script that uses cross-validation to evaluate a Linear Regression model on a synthetic dataset."
      ],
      "metadata": {
        "id": "bEzY5X8r_3e1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Generate data\n",
        "X, y = make_regression(n_samples=100, n_features=2, noise=5, random_state=42)\n",
        "\n",
        "# Cross-validation\n",
        "model = LinearRegression()\n",
        "scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
        "\n",
        "print(\"Cross-Validation R² Scores:\", scores)\n",
        "print(\"Average R² Score:\", scores.mean())\n"
      ],
      "metadata": {
        "id": "XDrqvvJ1_3m0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q25. Write a Python script that compares polynomial regression models of different degrees and prints the R-squared score for each."
      ],
      "metadata": {
        "id": "0G03zzUW_3vB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Synthetic data\n",
        "X = np.random.rand(100, 1) * 10\n",
        "y = 3 * X**2 + 2 * X + 5 + np.random.randn(100, 1) * 10\n",
        "\n",
        "# Compare degrees\n",
        "for degree in range(1, 5):\n",
        "    poly = PolynomialFeatures(degree)\n",
        "    X_poly = poly.fit_transform(X)\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_poly, y)\n",
        "    y_pred = model.predict(X_poly)\n",
        "    print(f\"Degree {degree} R² Score: {r2_score(y, y_pred):.4f}\")\n"
      ],
      "metadata": {
        "id": "-aZBNmIt_33h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}