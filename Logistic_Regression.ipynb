{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIiwwkANq76exAfFecTAHo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanika0216/python-Basics/blob/main/Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Theoretical**"
      ],
      "metadata": {
        "id": "hL5hHsF2faN7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. What is Logistic Regression, and how does it differ from Linear Regression?  \n",
        "Logistic Regression is a classification algorithm that predicts probabilities using the Sigmoid function, whereas Linear Regression is used for continuous value prediction.  \n",
        "\n",
        "### 2. What is the mathematical equation of Logistic Regression?  \n",
        "The equation is:  \n",
        "\\[\n",
        "P(Y=1|X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1X_1 + \\dots + \\beta_nX_n)}}\n",
        "\\]  \n",
        "\n",
        "### 3. Why do we use the Sigmoid function in Logistic Regression?  \n",
        "The Sigmoid function maps any real number into a probability range (0,1), making it suitable for binary classification.  \n",
        "\n",
        "### 4. What is the cost function of Logistic Regression?  \n",
        "Logistic Regression uses Log Loss (Cross-Entropy Loss), which is:  \n",
        "\\[\n",
        "J(\\theta) = -\\frac{1}{m} \\sum [y \\log(\\hat{y}) + (1 - y) \\log(1 - \\hat{y})]\n",
        "\\]  \n",
        "\n",
        "### 5. What is Regularization in Logistic Regression? Why is it needed?  \n",
        "Regularization (L1/L2) prevents overfitting by penalizing large coefficients, improving generalization.  \n",
        "\n",
        "### 6. Explain the difference between Lasso, Ridge, and Elastic Net regression.  \n",
        "- **Lasso (L1)**: Shrinks some coefficients to zero (feature selection).  \n",
        "- **Ridge (L2)**: Shrinks coefficients but does not set them to zero.  \n",
        "- **Elastic Net**: Combines both L1 and L2 penalties.  \n",
        "\n",
        "### 7. When should we use Elastic Net instead of Lasso or Ridge?  \n",
        "Elastic Net is preferred when features are highly correlated, as it balances feature selection (Lasso) and coefficient shrinkage (Ridge).  \n",
        "\n",
        "### 8. What is the impact of the regularization parameter (λ) in Logistic Regression?  \n",
        "A higher λ increases regularization, reducing overfitting but potentially underfitting; a lower λ reduces regularization, increasing overfitting risk.  \n",
        "\n",
        "### 9. What are the key assumptions of Logistic Regression?  \n",
        "- The dependent variable is binary.  \n",
        "- No multicollinearity among independent variables.  \n",
        "- The relationship between predictors and log-odds is linear.  \n",
        "\n",
        "### 10. What are some alternatives to Logistic Regression for classification tasks?  \n",
        "Alternatives include Decision Trees, Random Forest, SVM, Naïve Bayes, and Neural Networks.  \n",
        "\n",
        "### 11. What are Classification Evaluation Metrics?  \n",
        "Common metrics include Accuracy, Precision, Recall, F1-score, ROC-AUC, and Log Loss.  \n",
        "\n",
        "### 12. How does class imbalance affect Logistic Regression?  \n",
        "Class imbalance skews predictions toward the majority class, reducing model performance. Solutions include resampling and class weighting.  \n",
        "\n",
        "### 13. What is Hyperparameter Tuning in Logistic Regression?  \n",
        "It involves optimizing parameters like the regularization strength (C or λ) and solver choice to improve model performance.  \n",
        "\n",
        "### 14. What are different solvers in Logistic Regression? Which one should be used?  \n",
        "Solvers include **liblinear** (small datasets), **lbfgs & newton-cg** (multiclass), and **saga** (large datasets, L1 penalty).  \n",
        "\n",
        "### 15. How is Logistic Regression extended for multiclass classification?  \n",
        "It uses **One-vs-Rest (OvR)** or **Softmax Regression** to handle multiple classes.  \n",
        "\n",
        "### 16. What are the advantages and disadvantages of Logistic Regression?  \n",
        "**Advantages**: Simple, interpretable, works well with small datasets.  \n",
        "**Disadvantages**: Assumes linearity in log-odds, struggles with complex relationships.  \n",
        "\n",
        "### 17. What are some use cases of Logistic Regression?  \n",
        "It is used in spam detection, medical diagnosis, credit scoring, and customer churn prediction.  \n",
        "\n",
        "### 18. What is the difference between Softmax Regression and Logistic Regression?  \n",
        "Logistic Regression is for binary classification, while Softmax Regression extends it to multiclass classification.  \n",
        "\n",
        "### 19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?  \n",
        "OvR is preferred for high-dimensional data, while Softmax is more efficient when classes are mutually exclusive.  \n",
        "\n",
        "### 20. How do we interpret coefficients in Logistic Regression?  \n",
        "Coefficients represent log-odds changes; exponentiating them gives the odds ratio for each predictor.  "
      ],
      "metadata": {
        "id": "OtAM6sUmfaQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practical**"
      ],
      "metadata": {
        "id": "cFg8LRDKflJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy."
      ],
      "metadata": {
        "id": "p3TaJj3thHLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "qUvHSm5lh-qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy."
      ],
      "metadata": {
        "id": "zMlM5iEbiAP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression with L1 regularization\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"L1 Regularization Model Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "EVYOE-2liBuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients."
      ],
      "metadata": {
        "id": "n3Sy3FzdiDIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression with L2 regularization\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"L2 Regularization Model Accuracy: {accuracy:.4f}\")\n",
        "print(\"Model Coefficients:\", model.coef_)\n"
      ],
      "metadata": {
        "id": "R7VAnCbbiEll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')."
      ],
      "metadata": {
        "id": "sBWBcNRKiFzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression with Elastic Net regularization\n",
        "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Elastic Net Regularization Model Trained Successfully\")\n"
      ],
      "metadata": {
        "id": "PXo-PzI7iHHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'."
      ],
      "metadata": {
        "id": "OQdx1xVFiImL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression with One-vs-Rest (OvR) classification\n",
        "model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Multiclass OvR Model Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "B4TBDvzliJtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy."
      ],
      "metadata": {
        "id": "ry706B-ziLHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV\n",
        "grid_search = GridSearchCV(LogisticRegression(max_iter=200), param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print best parameters and accuracy\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best Accuracy: {grid_search.best_score_:.4f}\")\n"
      ],
      "metadata": {
        "id": "Ll__QZGEiMZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy."
      ],
      "metadata": {
        "id": "wdgOslmqiN_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Define Stratified K-Fold Cross-Validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Perform cross-validation\n",
        "scores = cross_val_score(model, X, y, cv=skf)\n",
        "\n",
        "print(f\"Average Accuracy from Stratified K-Fold CV: {scores.mean():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTRh0ISDiPVY",
        "outputId": "3172e856-3a60-4e49-f45d-6f5a5e3ca723"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy from Stratified K-Fold CV: 0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy."
      ],
      "metadata": {
        "id": "UZYK3TK2iQsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset from CSV file\n",
        "df = pd.read_csv('dataset.csv')  # Replace 'dataset.csv' with the actual file path\n",
        "\n",
        "# Assume the last column is the target variable\n",
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"CSV Dataset Model Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "DC09vie0iR47",
        "outputId": "bfae6539-bcfc-4628-b18f-14090cbec46a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9482d9aed2d0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load dataset from CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Replace 'dataset.csv' with the actual file path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Assume the last column is the target variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in\n",
        "Logistic Regression. Print the best parameters and accuracy"
      ],
      "metadata": {
        "id": "pRuka3z9j0hH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_dist = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(LogisticRegression(max_iter=200), param_dist, cv=5, n_iter=10, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best Parameters: {random_search.best_params_}\")\n",
        "print(f\"Best Accuracy: {random_search.best_score_:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DGbtvPuj9Bh",
        "outputId": "9364865c-6805-456a-ed65-9d0843a3f657"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'solver': 'saga', 'penalty': 'l2', 'C': 1}\n",
            "Best Accuracy: 0.9750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy"
      ],
      "metadata": {
        "id": "hdhD39RakPSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = OneVsOneClassifier(LogisticRegression(max_iter=200))\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"One-vs-One Multiclass Model Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "370GanH-kWTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary\n",
        "classification"
      ],
      "metadata": {
        "id": "2GNf5hbPkZTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HJywRB2pkecX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision,\n",
        "Recall, and F1-Score."
      ],
      "metadata": {
        "id": "gvxu2UHYkhOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "rqGmlS3CkmCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to\n",
        "improve model performance."
      ],
      "metadata": {
        "id": "HNnp2JMjkotz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=20, weights=[0.9, 0.1], random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(class_weight='balanced', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n"
      ],
      "metadata": {
        "id": "tTovlh3CktRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and\n",
        "evaluate performance"
      ],
      "metadata": {
        "id": "iS-XHRM71n9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df = pd.read_csv('titanic.csv')\n",
        "\n",
        "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
        "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "X = df.drop(columns=['Survived'])\n",
        "y = df['Survived']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "hdFbzSkk1s62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression\n",
        "model. Evaluate its accuracy and compare results with and without scaling."
      ],
      "metadata": {
        "id": "A68bwGzq1waU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model_without_scaling = LogisticRegression(max_iter=200)\n",
        "model_without_scaling.fit(X_train, y_train)\n",
        "accuracy_without_scaling = accuracy_score(y_test, model_without_scaling.predict(X_test))\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train\n"
      ],
      "metadata": {
        "id": "O6lJ_7or13i2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score."
      ],
      "metadata": {
        "id": "fRSxWFRN18YK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
        "\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n"
      ],
      "metadata": {
        "id": "4MhlO04T2KK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate\n",
        "accuracy."
      ],
      "metadata": {
        "id": "UKF4o5mk2RX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(C=0.5, max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Accuracy with C=0.5: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "-YD85dpY2Xjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. Write a Python program to train Logistic Regression and identify important features based on model\n",
        "coefficients."
      ],
      "metadata": {
        "id": "upryqElF2a1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "importance = model.coef_[0]\n",
        "feature_importance = pd.DataFrame({'Feature': feature_names, 'Importance': importance})\n",
        "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(feature_importance)\n"
      ],
      "metadata": {
        "id": "52pRrgX32eNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa\n",
        "Score."
      ],
      "metadata": {
        "id": "Fqbi2xCe2ieO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Cohen's Kappa Score: {kappa:.4f}\")\n"
      ],
      "metadata": {
        "id": "rEWtb52x2l8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary\n",
        "classification.\n"
      ],
      "metadata": {
        "id": "nZxlLTJl2ps1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
        "\n",
        "plt.plot(recall, precision, marker='.')\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZzkqlreO2uAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare\n",
        "their accuracy."
      ],
      "metadata": {
        "id": "lB7jCnis2w4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(solver=solver, max_iter=200)\n",
        "    model.fit(X_train, y_train)\n",
        "    accuracy = accuracy_score(y_test, model.predict(X_test))\n",
        "    print(f\"Accuracy with solver {solver}: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "QR9X_hr020jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Write a Python program to train Logistic Regression and evaluate its performance using Matthews\n",
        "Correlation Coefficient (MCC)."
      ],
      "metadata": {
        "id": "Wc2GSLtS22wW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(f\"Matthews Correlation Coefficient: {mcc:.4f}\")\n"
      ],
      "metadata": {
        "id": "8S9mfJC026ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. Write a Python program to train Logistic Regression on both raw and standardized data. Compare their\n",
        "accuracy to see the impact of feature scaling"
      ],
      "metadata": {
        "id": "Jp4PAngR2-UW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model_raw = LogisticRegression(max_iter=200)\n",
        "model_raw.fit(X_train, y_train)\n",
        "accuracy_raw = accuracy_score(y_test, model_raw.predict(X_test))\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression(max_iter=200)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "accuracy_scaled = accuracy_score(y_test, model_scaled.predict(X_test_scaled))\n",
        "\n",
        "print(f\"Accuracy without Scaling: {accuracy_raw:.4f}\")\n",
        "print(f\"Accuracy with Scaling: {accuracy_scaled:.4f}\")\n"
      ],
      "metadata": {
        "id": "YePiMISj3BG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using\n",
        "cross-validation."
      ],
      "metadata": {
        "id": "A-pwdHTb3De5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "C_values = [0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "for C in C_values:\n",
        "    model = LogisticRegression(C=C, max_iter=200)\n",
        "    scores = cross_val_score(model, X, y, cv=5)\n",
        "    print(f\"C={C}, Average Accuracy: {scores.mean():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zA2zdzDK3Go2",
        "outputId": "c155ebf7-5d0c-4bb5-bee7-4fc29039725f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C=0.01, Average Accuracy: 0.8600\n",
            "C=0.1, Average Accuracy: 0.9467\n",
            "C=1, Average Accuracy: 0.9733\n",
            "C=10, Average Accuracy: 0.9733\n",
            "C=100, Average Accuracy: 0.9800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to\n",
        "make predictions."
      ],
      "metadata": {
        "id": "360e-IhU3Im0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "joblib.dump(model, 'logistic_model.pkl')\n",
        "loaded_model = joblib.load('logistic_model.pkl')\n",
        "\n",
        "accuracy = loaded_model.score(X_test, y_test)\n",
        "print(f\"Loaded Model Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2yPd8k73MYR",
        "outputId": "19ef8b3d-57bc-4b00-f0d2-d2af8b9b6cf9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Model Accuracy: 1.0000\n"
          ]
        }
      ]
    }
  ]
}